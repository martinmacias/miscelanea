## Name Matching ##
# These functions help to identify how dissimilar is a column of names in a dataframe compared to a column of "official" names in another dataframe
# It relies in the stringdist package in R: https://cran.r-project.org/web/packages/stringdist/stringdist.pdf
# Jaro distance: measures the number of matching characters between two strings that are not too many
# positions apart and adds a penalty for matching characters that are transposed. 
# Jaro-winkler: corrects for the fact that errors are commonly done in the first few characters after the first mismatch
similarityFun<-function(unofficialName, officialData, officialNameCol, officialIDcol, method, p=0){
  
  # Packages
  require(stringdist)
  
  # Set up vector of official names
  official<-officialData[,officialNameCol]
  
  # Set up vector of official ID
  officialID<-officialData[,officialIDcol]
  
  # Build similarity vector
  simVector<-stringdist(a = unofficialName, b = official, method = method, p=p)
  
  # get: median, and two smallest values
  m<-median(simVector, na.rm = T)
  
  # Order the similarity vector and get the first value
  firstValue<-simVector[order(simVector)][1]
  
  # Get an index of in which position of the similarity vector 
  # is the smallest value
  indexFirst<-which(simVector==firstValue)
  
  
  # Solve ties #
  
  
  # If the index yields more than one value, means there are two values
  # with the smalles jw value
  if (length(indexFirst)>1) {
    
    # Therefore, make the first official name with the smallest value
    # the first name to be assigned as well as ID
    firstName<-official[indexFirst[1]]
    firstID<-officialID[indexFirst[1]]
    
    # Given is a tie, assign the smallest jw value to the second name
    secondValue<-firstValue
    
    # The index has more than one value
    # Thus, get the second element of the index 
    # to get the second assigned name
    secondName<-official[indexFirst[2]]
    secondID<-officialID[indexFirst[2]]
    #print(c(first, secondValue, second))
    
  } else {
    
    firstName<-official[indexFirst]
    firstID<-officialID[indexFirst]
    
    # Set up second largest value and index of second largest value
    secondValue<-simVector[order(simVector)][2]
    indexSecond<-which(simVector==secondValue)
    
    # If the index of the second value is larger than one,
    # then, there are two values with the second smallest value
    if (length(indexSecond)>1) {
      
      # Therefore, make the second official name with the first second smallest value
      # the second name to be assigned as well as ID
      secondName<-official[indexSecond[1]]
      secondID<-officialID[indexSecond[1]]
      
    } else{
      
      # Else, just make the second official name the 
      # single index that was selected 
      secondName<-official[indexSecond]
      secondID<-officialID[indexSecond]
    }}
  
  firstValue<-as.numeric(round(firstValue,3))
  secondValue<-as.numeric(round(secondValue,3))
  m<-round(m,3)
  
  # Yield result as a dataframe with the names and values
  result<-as.data.frame(cbind(firstID,
                              firstName,
                              firstValue,
                              secondID,
                              secondName,
                              secondValue,
                              m))
  # if (ncol(result)!=7) {
  #   print(m)
  # }
  
  return(result)
}


parseTablesFun<-function(unofficialData, unofficialCol, officialData, officialNameCol, officialIDcol, municipio=FALSE, method, p=0){
  
  print(unofficialData[1,1])
  # Assign vector of unofficial and official names
  unofficialName<-unofficialData[,unofficialCol]
  
  # Get similarity table
  similarityList<-lapply(unofficialName, 
                         similarityFun, 
                         officialData=officialData, 
                         officialNameCol=officialNameCol,
                         officialIDcol=officialIDcol,
                         method=method, 
                         p=p)
  
  similarityTable<-do.call(what = "rbind", args = similarityList)
  
  print(ncol(similarityTable))
  
  # if (municipio) {
  #   names(similarityTable)<-paste0(names(similarityTable),"Mun")
  # }
  
  result<-cbind(unofficialData, similarityTable)
  
  return(result)
}




##############################################################################################################################################################################################################################################################################
## st functions ##
nSmallest<- function(dataframe, n) {
  # Apply the sorting and head functions to each row
  resultMatrix <- apply(dataframe, 1, function(row){
    result<-order(row)[2:(n+1)]
    return(result)
  })
  return(resultMatrix)
}

st_nearest_neighbors<-function(x,y,idColx,idColy,n){
  # Inputs: two shapefiles, the id column of x, the id column of y to identify neighbors in y, n neighbors
  # Output: a data frame with a column of n ids for each element of x and a column of the n nearest neighbhors from y
  # Get ids from x
  ids<-unique(as.data.frame(x)[,idColx])
  print(length(ids))
  
  # Repeat ids as many neighbors as needed
  ids<-matrix(rep(ids, each=n),ncol=1)
  
  # Warnings
  if (st_crs(x)!=st_crs(y)) {
    stop("x and y projections differ")
  }
  
  # Calcualte distance matrix
  d<-st_distance(x = x,
                 y = y)
  
  # Convert distances to numeric
  d<-apply(X = as.data.frame(d), MARGIN = 2, FUN = as.numeric) 
  
  # Get indices of n nearest neighbors
  d<-nSmallest(dataframe = d, n = n)
  d<-matrix(d, ncol=1)
  
  # Create a matrix of the ids from x and the indices of the nearest elements of y
  d<-as.data.frame(cbind(ids,d))
  d[,2]<-as.data.frame(y)[,idColy][as.numeric(d[,2])]
  names(d)<-c("idsx","idsy")
  
  # Return matrix
  return(d)
}

# st_intersects_fast<-function(index,intersection,x,y,columnsx){
#   # Input: index, intersection list, data x, data y, columns to keep from x
#   # Output: a list with all the polygons from y intersected with the unique polygons from x
#   
#   require(sf)
#   
#   filter<-intersection[[index]]
#   
#   # take the information from favelas
#   subsetx<-as.data.frame(x)[index,c("cd_fvl_", "NM_AGSN")]
#   
#   # create a dataset of the info from favelas length of filter
#   subsetx<-as.data.frame(x = lapply(subsetx, rep, length(filter)))
#   
#   # subset of the information from the setores data with the filter
#   subsety<-setoresDataShape[filter,]
#   
#   # cbind subset of setores with dataset with info from favelas
#   output<-cbind(subsetx, subsety)
#   
#   # return the dataset 
#   return(output)
#   
# }

## Intersection 3 times faster than st_intersection
st_intersection_fast<-function(x,y, own_intersection=F, workers){
  
  # Inputs: two dataframes of the sf class
  # Output: a single dataframe with each sf feature from x that instersects with the sf features from y and all their variables
  
  # Packages
  require(sf)
  #require(doParallel)
  
  # Harmonize crs
  if (st_crs(x)!=st_crs(y)) {
    warning("x and y have different projections. Assigned projection of x to y")
    y<-st_transform(x = y, crs = st_crs(x))
  }
  
  ## 1. intersects list
  d<-st_intersects(x = x, y = y)
  
  if (own_intersection==T) {
    ## 2. Remove own intersection
    d<-lapply(seq_along(d),function(x){d[[x]][d[[x]]!=x]})
  }
  
  # 3. Parallel loop to intersect each subset of intersected features
  print("loop")
  
  ## Register workers
  cl<-makeCluster(workers)
  registerDoParallel(cl)
  
  result<-
    foreach(m=seq_along(d), .combine = rbind) %dopar% {
      
      # packages
      library(sf)
      
      #  for each element of the index list,
      #  extract index
      index<-d[[m]]
      
      # do the instersection
      #result<-st_intersection(x = favelas, y = fogoData[index,])
      
      # print result
      #result
      
      
      if (length(index)!=0) {
        #     # Subset data
        subx<-x[m,]
        suby<-y[index,]
        
        # Intersection
        int<-st_intersection(x = subx, y = suby)
        
        # Yield result
        int
      }
      
    }
  
  # Stop cluster
  stopCluster(cl)
  
  # Non-parallel
  # result<-lapply(seq_along(d), function(m){
  #   # Set index
  #   index<-d[[m]]
  # 
  #   if (length(index)!=0) {
  #     # Subset data
  #     subx<-x[m,]
  #     suby<-y[index,]
  # 
  #     # Intersection
  #     int<-st_intersection(x = subx, y = suby)
  # 
  #     # Yield result
  #     return(int)
  #    }
  # })

  # docall
  # print("docall")
  # result<-do.call(what = "rbind", args = result)
  
  return(result)
}


## functions to transform points to voronoi polygons
pointsToVoronoi <- function(points, crs=NULL){
  
  # convert points data to selected crs, other than EPSG 4326
  # because st_voronoi does not correctly triangulate lat lon data
  if (!is.null(crs)) {
    points<-st_transform(x = points, crs = crs)
  }
  
  
  ## points must be POINT geometry
  # check for point geometry and execute if true
  if(!all(st_geometry_type(points) == "POINT")){
    stop("points should be POINT geometries")
  }
  
  # make multipoint
  print("multipoint")
  g <- st_combine(st_geometry(points)) 
  
  
  # create voronoi polygons
  print("voronoi")
  v <- st_voronoi(g)
  
  # extract voronoi polygons from list
  print("extract")
  v <- st_collection_extract(v)
  
  # create a dataframe of polygons and new id
  print("df")
  v <- st_sf(data.frame(vorid=1:length(v), 
                        geometry=st_sfc(v)))
  
  return(v)
}


###############################################################################################################################################################################################################################################################################################################################################################
## Make columns with dummies out of columns with categorical variables ##
dummiesFun<-function(name, column){
  output<-ifelse(column==name,1,0)
  return(output)
}

dataDummiesFun<-function(dataset, pat, ending=NULL){
  
  ## Names of the dataset
  datasetNames<-names(dataset)
  
  ## Subdataset to analyze: keep the column with names to dichotomize
  datasetSub<-as.data.frame(dataset)[,grepl(pattern = pat, x = datasetNames)]
  
  ## Get unique values of names to dichotomize
  u<-unique(datasetSub)
  
  ## For each unique name, create an indicator
  l<-lapply(u, dummiesFun, column=datasetSub)
  
  ## Paste the rows of the dataset
  l<-as.data.frame(do.call(what = "cbind", args = l))
  
  ## Rename variables
  if (!is.null(ending)) {
    names(l)<-paste0(u,ending)
  } else {
    names(l)<-u
  }
  
  ## Stop if the datasets differ in length
  if (nrow(l)!=nrow(dataset)) {
    stop("Number of rows between the original dataset and the created dummies differ")
  }
  
  ## Paste columns to original dataset
  dataset<-cbind(dataset,l)
  
  return(dataset)
}



naDummiesFun<-function(dataset, pat, ending=NULL){
  
  ## Names of the dataset
  datasetNames<-names(dataset)
  
  ## Subdataset to analyze: keep the column with names to dichotomize
  datasetSub<-as.data.frame(dataset)[,grepl(pattern = pat, x = datasetNames)]
  
  ## For each column, convert to 1 if NA
  datasetSub<-apply(X = datasetSub,
                    MARGIN = 2,
                    function(x){
                      
                      ## Replace with NAs
                      r<-ifelse(is.na(x),1,0)
                      
                      return(r)
                    })
  
  datasetSub<-as.data.frame(datasetSub)
  
  ## Rename variables
  if (!is.null(ending)) {
    names(datasetSub)<-paste0(names(datasetSub),"NA")
  } 
  
  ## Paste results
  dataset<-cbind(dataset, datasetSub)
  
  ## Yield results
  return(dataset)
}



st_intersection_points<-function(polygons, points){
  
  # intersect dataframe of voronoi polygons with data from points
  print("intersection")
  intList<-st_intersects(x = polygons, y = points)
  
  # coordinates
  intCoords<-unlist(intList)
  
  if (length(intCoords)>nrow(polygons)) {
    print("Some polygon intersect with more than one point")
    stop()
  }

  # extract rows from points with coordinates
  points<-points[intCoords,]
  
  # rename geometry of polygon
  names(polygons)[names(polygons)=="geometry"]<-"geometrVoronoi"
  
  # cbind voronoiPolygons with points
  result<-cbind(polygons, points)
  
  return(result)
}













## Regression Models ##
multipleModelsFun<-function(outcome, data, id, time, covariate, controls=NULL, effect="twoways", controlsZero=NULL){
  
  # Filter data to only idtime, outcome, main covariates, controls
  # d<-data[,c(id,outcome,covariate,controls)]
  
  # Define names of outcome, covariate, and controls
  y<-outcome
  x<-covariate
  
  if (!is.null(controls)) {
    controls<-paste0(controls, collapse = "+")
    
    # String of formula
    f<-paste0(y, "~", x, "+", controls)
    
    
    f<-as.formula(object = f)
    print(f)
  } else {
    
    # String of formula
    f<-paste0(y, "~", x)
    f<-as.formula(object = f)
    print(f)
  }
  
  
  # Run models
  m<-plm(formula = f, data = data, effect = effect, model = "within", index = c(id, time))
  
  # Return result
  print(summary(m))
  return(m)
}


# For panel data models with clustered se
multipleModelsFun<-function(outcome, data, id, time, covariate, controls=NULL, effect="twoways", controlsZero=NULL, rse=F, rsemethod=NULL, rsetype=NULL, rsecluster=NULL){
  
  # Filter data to only idtime, outcome, main covariates, controls
  # d<-data[,c(id,outcome,covariate,controls,"admin3Name")]
  
  # Define names of outcome, covariate, and controls
  y<-outcome
  x<-covariate
  
  if (!is.null(controls)) {
    controls<-paste0(controls, collapse = "+")
    
    # String of formula
    f<-paste0(y, "~", x, "+", controls)
    
    
    f<-as.formula(object = f)
    print(f)
  } else {
    
    # String of formula
    f<-paste0(y, "~", x)
    f<-as.formula(object = f)
    print(f)
  }
  
  
  # Run models
  m<-plm(formula = f, data = data, effect = effect, model = "within", index = c(id, time))
  
  
  
  # Return result
  print(summary(m))
  
  ## Robust SE
  if (rse) {
    #mrse<-coeftest(m, vcovHC(m, method = rsemethod, type = rsetype, cluster = rsecluster))
    mrse<-coeftest(x = m, vcov. = function(x) vcovHC(x, method = rsemethod, type = rsetype, cluster = rsecluster))
    
    #mrse<-sqrt(diag(vcovHC(x = m, method = rsemethod, type = rsetype, cluster = rsecluster)))
    print(mrse)
    #print(coeftest(m, vcovHC(m, method = rsemethod, type = rsetype, cluster = rsecluster)))
  }
  
  return(m)
}

## Complex variables ##
cumsumResetFun <- function(vector) {
  cumulative_sum <- 0
  result <- numeric(length(vector))
  
  for (i in seq_along(vector)) {
    if (vector[i] == 0) {
      cumulative_sum <- 0
    } else {
      cumulative_sum <- cumulative_sum + vector[i]
    }
    
    result[i] <- cumulative_sum
  }
  
  return(result)
}

#########################################################
robustci<-function(model,rsemethod, rsetype=NULL, rsecluster,level, round=F){
  
  # Coefficients
  coefs<-coefficients(model)
  
  # Calculate robust std errors
  rse<-sqrt(diag(vcovHC(x = model, method = rsemethod, rsetype=rsetype, cluster = rsecluster)))
  
  # Confidence level
  if (level==95) {
    criticalval<-1.96
  } else{}
  
  if (level==90) {
    criticalval<-1.645
  }
  
  # CI upper
  ciupper<-coefs+(rse*criticalval)
  
  # CI lower
  cilower<-coefs-(rse*criticalval)
  
  # CIS
  result<-cbind(coefs, rse, ciupper, cilower)
  
  # Round ?
  if (round) {
    result<-round(result,3)
  }
  
  return(result)
}


################################################
Imputation
################################################
fillFun<-function(x, ids, cn){
  

# Goal: to redesign a predictor matrix for multiple imputation processes for a panel dataset, i.e., imputing the variables of each year at a time and using each year's variable to impute the next year's variables but not the other way around.
# Input: a list of rownames from a predictor matrix generated with mice including all variables in a dataset
# Output: a predictor matrix with a panel structure

  # Check if the package is installed; if not, install it
  if (!require(mice, quietly = TRUE)) {
    install.packages("mice")
    library(mice)
  } else {
    # If the package is already installed, just load it
    library(mice)
  }
  
  
  # Filter row and column names after id variables
  x<-x[!grepl(pattern = ids, x = x)]
  
  pat<-paste0(ids, collapse = "|")
  cn<-cn[!grepl(pattern = pat, x = cn)]
  
  # Extract year
  y<-as.numeric(gsub(pattern = "[a-zA-Z]", replacement = "", x = x))
  
  # Extract name
  n<-gsub(pattern = "[0-9]", replacement = "", x = x)
  
  # Extract years of other variables
  yy<-as.numeric(gsub(pattern = "[a-zA-Z]", replacement = "", x = cn))
  
  # Extract names of other variables
  nn<-gsub(pattern = "[0-9]", replacement = "", x = cn)
  print(nn)
  
  
  # Test whether the years of other variables are lower than or equal to
  yyl<-yy<y
  yye<-yy==y
  
  # Test whether the name of other variables are different
  nnd<-nn!=n
  nns<-n==nn
  
  # Create a vector for the predictor matrix with 1 if the column variable has a name different 
  # than the variable under analysis and the year is lower or equal than the variable
  t<-as.numeric((nns&yyl)|(nnd&yyl)|(nnd&yye))
  
  # Add a 0 at the beggining for CVEGEO
  t<-c(rep(0, length(ids)),t)
  
  return(t)
}




################################################
Python
################################################

# Function to detect messages from a function and store it in an empty list
# Define another function that stores the message in a list
def store_in_list(message_list, message_func, *args):
    
    # Redirect the standard output to capture the printed message
    sys.stdout = StringIO()
    message_func(*args)
    printed_message = sys.stdout.getvalue()
    sys.stdout = sys.__stdout__  # Reset the standard output

    # Store the captured message in the list
    message_list.append(printed_message.strip())

message_list=[]
store_in_list(message_list, geemap.ee_to_numpy, image, ["B4","B3","B2"], roi)
message_list
